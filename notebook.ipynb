{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkFCThYHxF_d"
      },
      "outputs": [],
      "source": [
        "# !apt install aria2\n",
        "# !pip3 install youtube-dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUkWYcNTxIl5"
      },
      "outputs": [],
      "source": [
        "# !youtube-dl -o \"tmp.m4a\" -f \"bestaudio[ext=m4a]\" --external-downloader aria2c --external-downloader-args \"-j 16 -x 16 -s 16 -k 1M\"  https://www.youtube.com/watch?v=G0d8nrMYMro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywUrVl71xK1L"
      },
      "outputs": [],
      "source": [
        "# !ffmpeg -ss 00:40:10.00 -i tmp.m4a -t 00:01:00.00 -c copy $TARGET_VOICE_FILE_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MPzVQK-HBy23"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = '/content'\n",
        "OUT_PATH = f'{DATA_PATH}/out/'\n",
        "TTS_PATH = f'{DATA_PATH}/TTS/'\n",
        "CONFIG_PATH = f'{DATA_PATH}/config.json'\n",
        "MODEL_PATH = f'{DATA_PATH}/best_model.pth.tar'\n",
        "CONFIG_SE_PATH = f'{DATA_PATH}/config_se.json'\n",
        "TTS_SPEAKERS_PATH = f'{DATA_PATH}/speakers.json'\n",
        "TTS_LANGUAGES_PATH = f'{DATA_PATH}/language_ids.json'\n",
        "CHECKPOINT_SE_PATH = f'{DATA_PATH}/SE_checkpoint.pth.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2omiAn3dYZFD"
      },
      "outputs": [],
      "source": [
        "TARGET_VOICE_FILE_PATH = f'{DATA_PATH}/target.ogg' # !!!\n",
        "SOURCE_VOICE_FILE_PATH = f'{DATA_PATH}/source.ogg' # !!!\n",
        "NORM_TARGET_VOICE_FILE_PATH = f'{DATA_PATH}/norm_target_voice.wav'\n",
        "NORM_SOURCE_VOICE_FILE_PATH = f'{DATA_PATH}/norm_source_voice.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZTfx7f_WDcpQ"
      },
      "outputs": [],
      "source": [
        "MODEL_FILE_ID = '1sgEjHt0lbPSEw9-FSbC_mBoOPwNi87YR'\n",
        "CONFIG_FILE_ID = '1-PfXD66l1ZpsZmJiC-vhL055CDSugLyP'\n",
        "CONFIG_SE_FILE_ID = '19cDrhZZ0PfKf2Zhr_ebB-QASRw844Tn1'\n",
        "TTS_SPEAKERS_FILE_ID = '1SZ9GE0CBM-xGstiXH2-O2QWdmSXsBKdC'\n",
        "TTS_LANGUAGES_FILE_ID = '1_Vb2_XHqcC0OcvRF82F883MTxfTRmerg'\n",
        "CHECKPOINT_SE_FILE_ID = '17JsW6h6TIh7-LkU2EvB_gnNrPcdBxt7X'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIGc-2mKC_VA"
      },
      "outputs": [],
      "source": [
        "!gdown --id $MODEL_FILE_ID -O $MODEL_PATH\n",
        "!gdown --id $CONFIG_FILE_ID -O $CONFIG_PATH\n",
        "!gdown --id $CONFIG_SE_FILE_ID -O $CONFIG_SE_PATH\n",
        "!gdown --id $TTS_SPEAKERS_FILE_ID -O $TTS_SPEAKERS_PATH\n",
        "!gdown --id $TTS_LANGUAGES_FILE_ID -O $TTS_LANGUAGES_PATH\n",
        "!gdown --id $CHECKPOINT_SE_FILE_ID -O $CHECKPOINT_SE_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWWFsKP1_fwL"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Edresson/Coqui-TTS -b multilingual-torchaudio-SE TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9iY44IAfBEdL"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q -e TTS/\n",
        "!pip3 install -q torchaudio==0.9.0\n",
        "!pip3 install -q ffmpeg-normalize==1.21.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8Rq9G8jlPO2B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import soundfile\n",
        "import subprocess\n",
        "\n",
        "sys.path.append(TTS_PATH)\n",
        "\n",
        "import TTS\n",
        "import TTS.tts\n",
        "import TTS.utils\n",
        "import TTS.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbGSCAAkE5Tm"
      },
      "outputs": [],
      "source": [
        "torch.set_grad_enabled(False)\n",
        "os.makedirs(OUT_PATH, exist_ok=True)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "sm_params = {\n",
        "    'encoder_model_path': CHECKPOINT_SE_PATH, \n",
        "    'encoder_config_path': CONFIG_SE_PATH, \n",
        "    'use_cuda': use_cuda\n",
        "}\n",
        "\n",
        "cfg = TTS.config.load_config(CONFIG_PATH)\n",
        "cfg.model_args['d_vector_file'] = TTS_SPEAKERS_PATH\n",
        "cfg.model_args['use_speaker_encoder_as_loss'] = False\n",
        "sm = TTS.tts.utils.speakers.SpeakerManager(**sm_params)\n",
        "ap = TTS.utils.audio.AudioProcessor(**cfg.audio)\n",
        "\n",
        "model = TTS.tts.models.setup_model(cfg)\n",
        "model.language_manager.set_language_ids_from_file(TTS_LANGUAGES_PATH)\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "model_weights = checkpoint['model'].copy()\n",
        "\n",
        "for key in list(model_weights.keys()):\n",
        "    if 'speaker_encoder' in key:\n",
        "        del model_weights[key]\n",
        "\n",
        "model.load_state_dict(model_weights)\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eNOKyoO4f4hV"
      },
      "outputs": [],
      "source": [
        "def norm(path, out_path):\n",
        "    cmd = ('ffmpeg-normalize', path, \n",
        "           '-f', '-nt', 'rms', '-t', '-27', \n",
        "           '-ar', '16000', '-o', out_path)\n",
        "    subprocess.call(cmd)\n",
        "\n",
        "norm(TARGET_VOICE_FILE_PATH, NORM_TARGET_VOICE_FILE_PATH)\n",
        "norm(SOURCE_VOICE_FILE_PATH, NORM_SOURCE_VOICE_FILE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZjB2EPaJSsO"
      },
      "outputs": [],
      "source": [
        "source_emb = sm.compute_d_vector_from_clip(NORM_SOURCE_VOICE_FILE_PATH)\n",
        "target_emb = sm.compute_d_vector_from_clip(NORM_TARGET_VOICE_FILE_PATH)\n",
        "source_audio, _ = soundfile.read(NORM_SOURCE_VOICE_FILE_PATH)\n",
        "source_spec = ap.spectrogram(source_audio)\n",
        "\n",
        "target_emb = torch.FloatTensor(target_emb).unsqueeze(0).to(device)\n",
        "source_emb = torch.FloatTensor(source_emb).unsqueeze(0).to(device)\n",
        "source_spec = torch.FloatTensor(source_spec).unsqueeze(0).to(device)\n",
        "y_lengths = torch.tensor([source_spec.size(-1)]).to(device)\n",
        "\n",
        "wav, _, _ = model.voice_conversion(source_spec, y_lengths, source_emb,  target_emb)\n",
        "ap.save_wav(wav.numpy(), 'out.wav')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXRlTdZhKPA7"
      },
      "outputs": [],
      "source": [
        "model.length_scale = 2.3\n",
        "model.inference_noise_scale = 0.3\n",
        "model.inference_noise_scale_dp = 0.3\n",
        "language_id = model.language_manager.language_id_mapping['en']\n",
        "source_emb = sm.compute_d_vector_from_clip(NORM_SOURCE_VOICE_FILE_PATH)\n",
        "target_emb = sm.compute_d_vector_from_clip(NORM_TARGET_VOICE_FILE_PATH)\n",
        "\n",
        "params = {\n",
        "    'style_wav': None, \n",
        "    'speaker_id': None, \n",
        "    'd_vector': target_emb, \n",
        "    'use_griffin_lim': True, \n",
        "    'do_trim_silence': False, \n",
        "    'language_id': language_id, \n",
        "    'enable_eos_bos_chars': cfg.enable_eos_bos_chars\n",
        "}\n",
        "\n",
        "text = \"It took me quite a long time to develop a voice, and now, that I have it, I am not going to be silent.\"\n",
        "wav, alignment, _, _ = TTS.tts.utils.synthesis.synthesis(model, text, cfg, use_cuda, ap, **params).values()\n",
        "ap.save_wav(wav, 'out.wav')\n",
        "gc.collect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}